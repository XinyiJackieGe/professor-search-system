<!DOCTYPE html>
<!--[if (lte IE 9) ]><html lang="en" class="no-js oldie"><![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--><html lang="en" class="no-js"><!--<![endif]-->
<head>
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<script src="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/lib/modernizr.min.js"></script>
	<link rel="shortcut icon" href="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/img/favicon.ico" type="image/x-icon" />
	<meta name="apple-mobile-web-app-title" content="NU Khoury">
	<link rel="apple-touch-icon" href="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/img/touchicon.png" />
	<link rel="apple-touch-icon-precomposed" href="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/img/touchicon.png" />
	<link rel="apple-touch-icon" sizes="180x180" href="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/img/touchicon-180.png" />

	<link href="https://fast.fonts.com/cssapi/cac43e8c-6965-44df-b8ca-9784607a3b53.css" rel="stylesheet" type="text/css"/>
	<link rel="stylesheet" type="text/css" media="all" href="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/prod/prod.min.css" />
	<link rel="stylesheet" type="text/css" media="all" href="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/lib/ccis.css" />
<!-- NU Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-WGQLLJ');</script>
<!-- End Google Tag Manager -->
<!-- Khoury Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KN6KMJB');</script>
<!-- End Google Tag Manager -->
<!-- Google CSE code -->
<script>
(function() {
var cx = '004538069614616277034:sltf9o73gg0';
var gcse = document.createElement('script');
gcse.type = 'text/javascript';
gcse.async = true;
gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
var s = document.getElementsByTagName('script')[0];
s.parentNode.insertBefore(gcse, s);
})();
</script>
<script type="text/javascript" src="https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/lib/google-cse.js"></script>
<!-- begin wp_head -->
<title>Ehsan Elhamifar &#8211; Khoury College of Computer Sciences</title>
<link rel='dns-prefetch' href='//s.w.org' />
<link rel='stylesheet' id='tribe-common-skeleton-style-css'  href='https://www.khoury.northeastern.edu/wp-content/plugins/the-events-calendar/common/src/resources/css/common-skeleton.min.css?ver=4.11.5.1' type='text/css' media='all' />
<link rel='stylesheet' id='tribe-tooltip-css'  href='https://www.khoury.northeastern.edu/wp-content/plugins/the-events-calendar/common/src/resources/css/tooltip.min.css?ver=4.11.5.1' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-library-css'  href='https://www.khoury.northeastern.edu/wp-includes/css/dist/block-library/style.min.css?ver=5.3.2' type='text/css' media='all' />
<script type='text/javascript' src='https://www.khoury.northeastern.edu/wp-includes/js/jquery/jquery.js?ver=1.12.4-wp'></script>
<script type='text/javascript' src='https://www.khoury.northeastern.edu/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1'></script>
<link rel='https://api.w.org/' href='https://www.khoury.northeastern.edu/wp-json/' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://www.khoury.northeastern.edu/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://www.khoury.northeastern.edu/wp-includes/wlwmanifest.xml" /> 
<link rel='prev' title='Gene Cooperman' href='https://www.khoury.northeastern.edu/people/gene-cooperman/' />
<link rel='next' title='Tina Eliassi-Rad' href='https://www.khoury.northeastern.edu/people/tina-eliassi-rad/' />
<meta name="generator" content="WordPress 5.3.2" />
<link rel="canonical" href="https://www.khoury.northeastern.edu/people/ehsan-elhamifar/" />
<link rel='shortlink' href='https://www.khoury.northeastern.edu/?p=2308' />
<link rel="alternate" type="application/json+oembed" href="https://www.khoury.northeastern.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.khoury.northeastern.edu%2Fpeople%2Fehsan-elhamifar%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://www.khoury.northeastern.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.khoury.northeastern.edu%2Fpeople%2Fehsan-elhamifar%2F&#038;format=xml" />
<meta name="tec-api-version" content="v1"><meta name="tec-api-origin" content="https://www.khoury.northeastern.edu"><link rel="https://theeventscalendar.com/" href="https://www.khoury.northeastern.edu/wp-json/tribe/events/v1/" /><!-- end wp_head -->

</head>



<body class="people-template-default single single-people postid-2308 tribe-no-js tribe-events-filter-view tribe-filters-closed tribe-filters-horizontal">
<!-- NU Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WGQLLJ" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- Khoury Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KN6KMJB" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->	<a id="top" class="sr-only" href="#main-content">Skip to main content</a>

	<header id="site-header" role="banner">

		<div id="contact-region">
			<div class="container">
				<div class="contact-contents expanded">

					
					<div class="contact-col">
						<h4>Main</h4>
<a href="mailto:khoury@northeastern.edu">khoury@northeastern.edu</a>
<a href="tel:6173732462">617.373.2462</a>
<a href="http://www.northeastern.edu/nupd/campus-safety/">Campus Safety</a>
<a href="https://www.northeastern.edu/campusmap/map/index.html">Campus Map</a>					</div>

					<div class="contact-col">
						<h4>Undergraduate</h4>
<a href="tel:6173736519">617.373.6519</a>
<a href="mailto:admissions@northeastern.edu">admissions@northeastern.edu</a>
<a href="mailto:khoury-advising@northeastern.edu">khoury-advising@northeastern.edu</a>					</div>

					<div class="contact-col">
						<h4>Graduate</h4>
<a href="tel:6173738613">617.373.5545</a>
<a href="mailto:khoury-gradschool@northeastern.edu">khoury-gradschool@northeastern.edu</a>					</div>

					
					<nav id="menu-contact-header" class="contact-col" aria-label="Contact">
						<ul id="menu-contact-menu" class="menu menu-contact menu-vertical"><li id="menu-item-3010" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-3010"><a rel="nofollow" href="#">Contact &#8211; Parent</a>
<ul class="sub-menu">
	<li id="menu-item-4598" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-4598"><a href="https://www.khoury.northeastern.edu/directions-and-parking/">Directions &#038; Parking</a></li>
	<li id="menu-item-2530" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2530"><a href="https://www.khoury.northeastern.edu/facilities/">Facilities</a></li>
	<li id="menu-item-5831" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-5831"><a href="https://www.khoury.northeastern.edu/systems/">Systems</a></li>
	<li id="menu-item-4627" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-4627"><a href="https://www.khoury.northeastern.edu/about/">About</a></li>
	<li id="menu-item-6161" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-6161"><a href="https://www.ccis.northeastern.edu/events/">Events</a></li>
	<li id="menu-item-4629" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-4629"><a href="https://www.khoury.northeastern.edu/news/">News</a></li>
</ul>
</li>
</ul>					</nav>
				</div>
			</div>
		</div>

		<div class="container">

			<div id="utilities-region">
				<div id="utilities">
					<nav id="menu-utility" aria-label="Utility">
						<ul id="menu-utility-menu" class="menu menu-utility menu-horizontal"><li id="menu-item-2766" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-2766"><a rel="nofollow" href="#">Utility &#8211; Parent</a>
<ul class="sub-menu">
	<li id="menu-item-2294" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2294"><a href="https://www.khoury.northeastern.edu/open-positions/">We’re hiring</a></li>
	<li id="menu-item-13723" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-13723"><a href="https://www.khoury.northeastern.edu/current-students/">Current Students</a></li>
	<li id="menu-item-403" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-403"><a href="https://www.khoury.northeastern.edu/industry/">Industry</a></li>
	<li id="menu-item-7849" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-7849"><a href="https://www.khoury.northeastern.edu/diversity/">Diversity</a></li>
	<li id="menu-item-402" class="toggle menu-item menu-item-type-post_type menu-item-object-page menu-item-402"><a href="https://www.khoury.northeastern.edu/contact/">Contact</a></li>
</ul>
</li>
</ul>					</nav>
					<form role="search" id="searchform-q" onsubmit="return submitQuery()">
    <label class="screen-reader-text" for="q">Search</label>
    <input type="text" placeholder="Search" value="" name="q" id="q" />
    <button type="submit" id="searchsubmit" value="Search"></button>
</form>
<noscript>
    <form role="search" method="get" id="searchform" action="https://www.khoury.northeastern.edu/">
        <label class="screen-reader-text" for="s">Search</label>
        <input type="text" placeholder="Search"  value="" name="s" id="s" />
	<button type="submit" id="searchsubmit" value="Search"></button>
    </form>
</noscript>
				</div>
			</div><!-- /#utilities-region -->

			<div id="branding-region">

				<h1 id="site-logo">
					<a href="https://www.khoury.northeastern.edu">
						<span>Khoury College of Computer Sciences</span>
						<!-- main Khoury logo -->
						<img src="/wp-content/uploads/2019/02/nu-khoury-lockup.png" alt="college lockup" />
					</a>
				</h1>
			</div><!-- /#branding-region -->


			<nav role="navigation" id="menu-primary" aria-label="Primary">
				<!-- main nav here -->
				<ul class="menu menu-primary menu-horizontal">
										<li class="bucket">
						<a class="toggle" href="#menu-academics">Academics</a><div class="expanded"><div class="menu-description"><p><strong>Computer science for everyone</strong><br />
Now more than ever, computer science is everywhere. Our innovative, interdisciplinary programs deliver the knowledge and perspective you need to succeed in a highly demanding job market.</p>
</div><ul id="menu-academics" class="submenu menu-vertical"><li id="menu-item-2222" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2222"><a rel="nofollow" href="https://www.khoury.northeastern.edu/academics/">Academics – FLYOUT</a>
<ul class="sub-menu">
	<li id="menu-item-980" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-980"><a href="https://www.khoury.northeastern.edu/academics/undergraduate/">Undergraduate</a></li>
	<li id="menu-item-978" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-978"><a href="https://www.khoury.northeastern.edu/academics/masters/">Masters</a></li>
	<li id="menu-item-979" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-979"><a href="https://www.khoury.northeastern.edu/academics/phd/">PhD</a></li>
	<li id="menu-item-973" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-973"><a href="https://www.khoury.northeastern.edu/academics/certificate/">Certificate</a></li>
	<li id="menu-item-3266" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-3266"><a href="https://www.khoury.northeastern.edu/academics/courses/">Courses</a></li>
</ul>
</li>
</ul></div>					</li>
											<li class="bucket">
						<a class="toggle" href="#menu-research">Research</a><div class="expanded"><div class="menu-description"><p><strong>Solving today’s challenges</strong><br />
Bringing together students and faculty across disciplines, the Khoury research community finds impactful solutions to everyday problems.</p>
</div><ul id="menu-research" class="submenu menu-vertical"><li id="menu-item-2307" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2307"><a rel="nofollow" href="https://www.khoury.northeastern.edu/research/">Research</a>
<ul class="sub-menu">
	<li id="menu-item-400" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-400"><a href="https://www.khoury.northeastern.edu/research/research-areas/">Research Areas</a></li>
	<li id="menu-item-1192" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1192"><a href="https://www.khoury.northeastern.edu/research/research-projects/">Research Projects</a></li>
	<li id="menu-item-998" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-998"><a href="https://www.khoury.northeastern.edu/research/labs-groups/">Labs and Groups</a></li>
	<li id="menu-item-1021" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1021"><a href="https://www.khoury.northeastern.edu/research/institutes/">Institutes and Centers</a></li>
	<li id="menu-item-1022" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1022"><a href="https://www.khoury.northeastern.edu/research/speaker-series/">Speaker Series</a></li>
</ul>
</li>
</ul></div>					</li>
											<li class="bucket">
						<a class="toggle" href="#menu-coop">Experiential Learning & Co-op</a><div class="expanded"><div class="menu-description"><p><strong>A real-world education</strong><br />
Khoury experiential learning and co-op programs deliver a hands-on education to enhance your studies—and advance your career.</p>
</div><ul id="menu-experiential-learning-co-op" class="submenu menu-vertical"><li id="menu-item-399" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-399"><a rel="nofollow" href="https://www.khoury.northeastern.edu/experiential-learning/">Experiential Learning &#038; Co-op – FLYOUT</a>
<ul class="sub-menu">
	<li id="menu-item-2256" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2256"><a href="https://www.khoury.northeastern.edu/experiential-learning/undergraduate/">Undergraduate</a></li>
	<li id="menu-item-2262" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2262"><a href="https://www.khoury.northeastern.edu/experiential-learning/masters/">Masters</a></li>
	<li id="menu-item-2264" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2264"><a href="https://www.khoury.northeastern.edu/experiential-learning/phd/">PhD</a></li>
	<li id="menu-item-2265" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2265"><a href="https://www.khoury.northeastern.edu/experiential-learning/employers/">Employers</a></li>
</ul>
</li>
</ul></div>					</li>
											<li class="bucket current-bucket">
						<a class="toggle" href="#menu-people">People</a><div class="expanded"><div class="menu-description"><p><strong>Experienced, engaged, inspiring</strong><br />
Our renowned faculty shape minds, spark innovation, and inspire ideas. Our dedicated advisors and coordinators build connections and confidence. Our committed staff provide support every step of the way.</p>
</div><ul id="menu-people" class="submenu menu-vertical"><li id="menu-item-2282" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2282"><a rel="nofollow" href="https://www.khoury.northeastern.edu/people/">People</a>
<ul class="sub-menu">
	<li id="menu-item-727" class="menu-item menu-item-type-taxonomy menu-item-object-role current-people-ancestor current-menu-parent current-people-parent menu-item-727"><a href="https://www.khoury.northeastern.edu/role/tenured-and-tenure-track-faculty/">Tenured and Tenure Track Faculty</a></li>
	<li id="menu-item-8882" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-8882"><a href="https://www.khoury.northeastern.edu/role/professors-practice/">Professors of the Practice</a></li>
	<li id="menu-item-733" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-733"><a href="https://www.khoury.northeastern.edu/role/teaching-faculty/">Teaching Faculty</a></li>
	<li id="menu-item-728" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-728"><a href="https://www.khoury.northeastern.edu/role/research-faculty/">Research Faculty and Staff</a></li>
	<li id="menu-item-5778" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-5778"><a href="https://www.khoury.northeastern.edu/role/courtesy-appointments/">Courtesy Appointments</a></li>
	<li id="menu-item-725" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-725"><a href="https://www.khoury.northeastern.edu/role/co-op-and-advising/">Co-op and Advising</a></li>
	<li id="menu-item-726" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-726"><a href="https://www.khoury.northeastern.edu/role/administrative-staff/">Administrative Staff</a></li>
	<li id="menu-item-729" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-729"><a href="https://www.khoury.northeastern.edu/role/systems-staff/">Systems Staff</a></li>
	<li id="menu-item-730" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-730"><a href="https://www.khoury.northeastern.edu/role/post-docs/">Post Docs</a></li>
	<li id="menu-item-731" class="menu-item menu-item-type-taxonomy menu-item-object-role menu-item-731"><a href="https://www.khoury.northeastern.edu/role/phd-students/">PhD Students</a></li>
	<li id="menu-item-413" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-413"><a href="https://www.khoury.northeastern.edu/people-view-all/">View All</a></li>
</ul>
</li>
</ul></div>					</li>
											<li class="bucket">
						<a class="toggle" href="#menu-alumni">Alumni & Friends</a><div class="expanded"><div class="menu-description"><p><strong>This is your community</strong><br />
It’s time to get involved and give back. Engage and explore. Connect and keep in touch. Your Khoury community welcomes you!  </p>
</div><ul id="menu-alumni-friends" class="submenu menu-vertical"><li id="menu-item-2281" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2281"><a rel="nofollow" href="https://www.khoury.northeastern.edu/alumni-and-friends/">Alumni &#038; Friends – FLYOUT</a>
<ul class="sub-menu">
	<li id="menu-item-2283" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2283"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/welcome-back/">Welcome Back</a></li>
	<li id="menu-item-1140" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1140"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/alumni-news-events/">Alumni News &#038; Events</a></li>
	<li id="menu-item-7062" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-7062"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/class-notes/">Alumni Class Notes</a></li>
	<li id="menu-item-1145" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1145"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/parents/">Parents</a></li>
	<li id="menu-item-1141" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1141"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/connect/">Connect</a></li>
	<li id="menu-item-2284" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-2284"><a href="https://careers.northeastern.edu/">Career Services</a></li>
	<li id="menu-item-1142" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-1142"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/give/">Give</a></li>
</ul>
</li>
</ul></div>					</li>
										</ul>
			</nav>


		</div> <!-- /.container -->

	</header>
		<main class="container" id="main-content">
		<div class="row">
			<section id="primary-content">
								<article class="people">
					<header class="people-header">
						<div class="section-inner">
						<h1 class="page-title">
													<a href="https://www.khoury.northeastern.edu/people/ehsan-elhamifar/" title="Ehsan Elhamifar">
							Ehsan Elhamifar							</a>
												</h1>

								<h2>
							Assistant Professor						</h2>
							<h2>
							Affiliate Faculty with the Department of Electrical and Computer Engineering						</h2>
	
							<section class="related-groups related-section">
						<div class="section-inner">
															<a href="http://www.ccs.neu.edu/home/eelhami/mcadsLab.htm" class="button-red button-arrow-right">MCADS Lab</a>
													</div>
					</section>
	
								<img width="2400" height="1000" src="https://www.khoury.northeastern.edu/wp-content/uploads/2016/02/linderpix-NEU-5478-hero.jpg" class="attachment-post-thumbnail size-post-thumbnail wp-post-image" alt="" srcset="https://www.khoury.northeastern.edu/wp-content/uploads/2016/02/linderpix-NEU-5478-hero.jpg 2400w, https://www.khoury.northeastern.edu/wp-content/uploads/2016/02/linderpix-NEU-5478-hero-800x333.jpg 800w, https://www.khoury.northeastern.edu/wp-content/uploads/2016/02/linderpix-NEU-5478-hero-1500x625.jpg 1500w" sizes="(max-width: 2400px) 100vw, 2400px" />						</div>
					</header>


					<section class="people-info">
								<div class="supplemental">
							<div class="contact-block">
																<h2 class="section-title">
									Contact
								</h2>
								<div class="contact-links">
									<p class="personal-site"><span>W</span><a href="http://www.ccs.neu.edu/home/eelhami">Personal site</a>									<p class="google-scholar"><span>G</span><a href="https://scholar.google.com/citations?user=cpgUf6wAAAAJ&hl=en&oi=ao">Google Scholar</a>																		<p class="contact-email"><span>E</span><a href="mailto:e&#101;l&#104;&#97;&#109;i&#64;&#99;&#99;s&#46;&#110;e&#117;.&#101;&#100;u">ee&#108;&#104;ami&#64;cc&#115;&#46;&#110;&#101;u&#46;&#101;d&#117;</a>
																			<p class="contact-phone"><span>T</span><a href="tel:6173736535">617.373.6535</a>								</div>
																	<div class="address">
										<h2 class="section-title">
											Office Location
										</h2>
										<p>440 Huntington Avenue<br />
310E West Village H<br />
Boston, MA  02115<br />
</p>
									</div>
																		<div class="address-mailing">
										<h2 class="section-title">
											Mailing Address
										</h2>
									<p>Northeastern University <br />
ATTN: Ehsan Elhamifar, 202 WVH<br />
360 Huntington Avenue<br />
Boston, MA  02115<br />
</p>
									</div>
																</div>
						</div>
	
							<div class="main-content">
							<h2>Research Interests</h2>
<ul>
<li>Machine Learning: subset selection, zero and few shot learning, manifold clustering, high-rank matrix completion, nonlinear dynamical models, deep neural networks</li>
<li>Computer Vision: procedure learning, video summarization, large-scale multi-label recognition, motion and activity segmentation, active learning for visual data</li>
<li>Optimization: sparse and low-rank recovery, structured submodular maximization, convex and non-convex optimization</li>
</ul>
<h2>Education</h2>
<ul>
<li>PhD in Electrical and Computer Engineering, Johns Hopkins University</li>
<li>MS in Applied Mathematics and Statistics, Johns Hopkins University</li>
<li>MS in Electrical Engineering, Sharif University of Technology</li>
</ul>
<h2>Biography</h2>
<p>Ehsan Elhamifar is an Assistant Professor in the Khoury College of Computer Sciences and is the director of the Mathematical, Computational and Applied Data Science (MCADS) Lab at Northeastern University. He is affiliated with the Electrical and Computer Engineering Department at Northeastern. Prof. Elhamifar is a recipient of the DARPA Young Faculty Award and the NSF CISE Career Research Initiation Initiative Award. Previously, he was a postdoctoral scholar in the Electrical Engineering and Computer Science department at UC Berkeley. Prof. Elhamifar obtained his PhD from the Electrical and Computer Engineering department at the Johns Hopkins University.</p>
<p>Prof. Elhamifar’s research areas are machine learning, computer vision and optimization. He is interested in developing scalable, robust and provable algorithms that can address challenges of complex and massive high-dimensional data. He works on applications of these tools in computer vision and robotics among others. Specifically, he uses tools from convex, nonconvex and submodular optimization, sparse and low-rank modeling, deep learning, high-dimensional statistics and graphical models to develop algorithms and theory and applies them to solve real-world challenging problems, including big data summarization, procedure learning from instructional data, large-scale recognition with small labeled data and active learning for visual data.</p>
													</div>
					</section>

		

							<section class="recent-publications related-section">
						<div class="section-inner">
							<h2 class="section-title">
								Recent Publications
							</h2>
											<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://khoury.neu.edu/home/eelhami/publications/SupFL_NeurIPS19.pdf" title="Deep Supervised Summarization: Algorithm and Application to Learning Instructions">
								Deep Supervised Summarization: Algorithm and Application to Learning Instructions							</a>
												</h3>
												<p>Deep Supervised Summarization: Algorithm and Application to Learning Instructions C. Xu and E. Elhamifar, Neural Information Processing Systems (NeurIPS), 2019.</p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>We address the problem of finding representative points of datasets by learning from multiple datasets and their ground-truth summaries. We develop a supervised subset selection framework, based on the facility location utility function, which learns to map datasets to their ground-truth representatives. To do so, we propose to learn representations of data so that the input of transformed data to the facility location recovers their ground-truth representatives. Given the NP-hardness of the utility function, we consider its convex relaxation based on sparse representation and investigate conditions under which the solution of the convex optimization recovers ground-truth representatives of each dataset. We design a loss function whose minimization over the parameters of the data representation network leads to satisfying the theoretical conditions, hence guaranteeing recovering groundtruth summaries. Given the non-convexity of the loss function, we develop an efficient learning scheme that alternates between representation learning by minimizing our proposed loss given the current assignments of points to ground-truth representatives and updating assignments given the current data representation. By experiments on the problem of learning key-steps (subactivities) of instructional videos, we show that our proposed framework improves the state-of-the-art supervised subset selection algorithms.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/ICCV19-ProceL-Ehsan.pdf" title="Unsupervised Procedure Learning via Joint Dynamic Summarization">
								Unsupervised Procedure Learning via Joint Dynamic Summarization							</a>
												</h3>
												<p>Unsupervised Procedure Learning via Joint Dynamic Summarization. E. Elhamifar and Z. Naing, International Conference on Computer Vision (ICCV), 2019.</p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>We address the problem of unsupervised procedure learning from unconstrained instructional videos. Our goal is to produce a summary of the procedure key-steps and their ordering needed to perform a given task, as well as localization of the key-steps in videos. We develop a collaborative sequential subset selection framework, where we build a dynamic model on videos by learning states and transitions between them, where states correspond to different subactivities, including background and procedure steps. To extract procedure key-steps, we develop an optimization framework that finds a sequence of a small number of states that well represents all videos and is compatible with the state transition model. Given that our proposed optimization is non-convex and NP-hard, we develop a fast greedy algorithm whose complexity is linear in the length of the videos and the number of states of the dynamic model, hence, scales to large datasets. Under appropriate conditions on the transition model, our proposed formulation is approximately submodular, hence, comes with performance guarantees. We also present ProceL, a new multimodal dataset of 47.3 hours of videos and their transcripts from diverse tasks, for procedure learning evaluation. By extensive experiments, we show that our framework significantly improves the state of the art performance.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/SeqFL_ICML19.pdf" title="Facility Location: Approximate Submodularity and Greedy Algorithm">
								Facility Location: Approximate Submodularity and Greedy Algorithm							</a>
												</h3>
												<p>Facility Location: Approximate Submodularity and Greedy Algorithm, E. Elhamifar, International Conference on Machine Learning (ICML), 2019.</p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>We develop and analyze a novel utility function and a fast optimization algorithm for subset selection in sequential data that incorporates the dynamic model of data. We propose a cardinality constrained sequential facility location function that finds a fixed number of representatives, where the sequence of representatives is compatible with the dynamic model and well encodes the data. As maximizing this new objective function is NPhard, we develop a fast greedy algorithm based on submodular maximization. Unlike the conventional facility location, the computation of the marginal gain in our case cannot be done by operations on each item independently. We exploit the sequential structure of the problem and develop an efficient dynamic programming-based algorithm that computes the marginal gain exactly. We investigate conditions on the dynamic model, under which our utility function is (ε-approximately) submodular, hence, the greedy algorithm comes with performance guarantees. By experiments on synthetic data and the problem of procedure learning from instructional videos, we show that our framework significantly improves the computational time, achieves better objective function values and obtains more coherent summaries.</p>
						</div>
					</div>
				</article>
							<!-- put more pubs link here -->
															<a href="http://www.ccs.neu.edu/home/eelhami/publications.htm" class="button-arrow-external button-red">More Publications</a>
													</div>
					</section>
	
						<section class="previous-publications related-section">
						<div class="section-inner">
							<h2 class="section-title">
								Previous Publications
							</h2>
																					<div class="accordion-item">
								<h3 class="accordion-label">2018</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/HRMC-SideInfo-AAAI18-Ehsan.pdf" title="High-Rank Matrix Completion with Side Information">
								High-Rank Matrix Completion with Side Information							</a>
												</h3>
												<p>Y. Wang and E. Elhamifar AAAI Conference on Artificial Intelligence (AAAI), 2018. </p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>We address the problem of high-rank matrix completion with side information. In contrast to existing work dealing with side information, which assume that the data matrix is low-rank, we consider the more general scenario where the columns of the data matrix are drawn from a union of lowdimensional subspaces, which can lead to a high rank matrix. Our goal is to complete the matrix while taking advantage of the side information. To do so, we use the self-expressive property of the data, searching for a sparse representation of each column of matrix as a combination of a few other columns. More specifically, we propose a factorization of the data matrix as the product of side information matrices with an unknown interaction matrix, under which each column of the data matrix can be reconstructed using a sparse combination of other columns. As our proposed optimization, searching for missing entries and sparse coefficients, is non-convex and NP-hard, we propose a lifting framework, where we couple sparse coefficients and missing values and define an equivalent optimization that is amenable to convex relaxation. We also propose a fast implementation of our convex framework using a Linearized Alternating Direction Method. By extensive experiments on both synthetic and real data, and, in particular, by studying the problem of multi-label learning, we demonstrate that our method outperforms existing techniques in both low-rank and high-rank data regimes.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2017</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/SeqSS-NIPS17-Ehsan.pdf" title="Subset Selection and Summarization in Sequential Data">
								Subset Selection and Summarization in Sequential Data							</a>
												</h3>
												<p>E. Elhamifar and M. C. De Paolis Kaluza; Neural Information Processing Systems (NIPS), 2017. </p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>Subset selection, which is the task of finding a small subset of representative items from a large ground set, finds numerous applications in different areas. Sequential data, including time-series and ordered data, contain important structural relationships among items, imposed by underlying dynamic models of data, that should play a vital role in the selection of representatives. However, nearly all existing subset selection techniques ignore underlying dynamics of data and treat items independently, leading to incompatible sets of representatives. In this paper, we develop a new framework for sequential subset selection that finds a set of representatives compatible with the dynamic models of data. To do so, we equip items with transition dynamic models and pose the problem as an integer binary optimization over assignments of sequential items to representatives, that leads to high encoding, diversity and  transition potentials. Our formulation generalizes the well-known facility location objective to deal with sequential data, incorporating transition<br />
dynamics among facilities. As the proposed formulation is non-convex, we derive a max-sum message passing algorithm to solve the problem efficiently. Experiments on synthetic and real data, including instructional video summarization, show that our sequential subset selection framework not only achieves better encoding and diversity than the state of the art, but also successfully incorporates dynamics of data, leading to compatible representatives.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/onlineSS_CVPR17-Ehsan.pdf" title="Online Summarization via Submodular and Convex Optimization">
								Online Summarization via Submodular and Convex Optimization							</a>
												</h3>
												<p>E. Elhamifar and M. C. De Paolis Kaluza  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017. </p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>We consider the problem of subset selection in the online setting, where data arrive incrementally. Instead of storing and running subset selection on the entire dataset, we propose an incremental subset selection framework that, at each time instant, uses the previously selected set of representatives and the new batch of data in order to update the set of representatives. We cast the problem as an integer binary optimization minimizing the encoding cost of the data via representatives regularized by the number of selected items. As the proposed optimization is, in general, NP-hard and non-convex, we study a greedy approach based on unconstrained submodular optimization and also propose an efficient convex relaxation. We show that, under appropriate conditions, the solution of our proposed convex algorithm achieves the global optimal solution of the non-convex problem. Our results also address the conventional problem of subset selection in the offline setting, as a special case. By extensive experiments on the problem of video summarization,<br />
we demonstrate that our proposed online subset selection algorithms perform well on real data, capturing diverse representative events in videos, while they obtain objective function values close to the offline setting.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2016</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://arxiv.org/abs/1407.6810" title="Dissimilarity-based Sparse Subset Selection">
								Dissimilarity-based Sparse Subset Selection							</a>
												</h3>
												<p>Dissimilarity-based Sparse Subset Selection, E. Elhamifar, G. Sapiro and S. Sastry, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2016.</p>
												<div class="publication-abstract">
							<p>Finding an informative subset of a large number of data points or models is at the center of many problems in machine learning, computer vision, bio/health informatics and image/signal processing. Given pairwise dissimilarities between the elements of a `source set&#8217; and a `target set,&#8217; we consider the problem of finding a subset of the source set, called representatives or exemplars, that can efficiently describe the target set. We formulate the problem as a row-sparsity regularized trace minimization problem. Since the proposed formulation is, in general, an NP-hard problem, we consider a convex relaxation. The solution of our proposed optimization program finds the representatives and the probability that each element of the target set is associated with the representatives. We analyze the solution of our proposed optimization as a function of the regularization parameter. We show that when the two sets jointly partition into multiple groups, the solution of our proposed optimization program finds representatives from all groups and reveals clustering of the sets. In addition, we show that our proposed formulation can effectively deal with outliers. Our algorithm works with arbitrary dissimilarities, which can be asymmetric or violate the triangle inequality. To efficiently implement our proposed algorithm, we consider an Alternating Direction Method of Multipliers (ADMM) framework, which results in quadratic complexity in the problem size. We show that the ADMM implementation allows to parallelize the algorithm, hence further reducing the computational cost. Finally, by experiments on real-world datasets, we show that our proposed algorithm improves the state of the art on the two problems of scene categorization using representative images and time-series modeling and segmentation using representative models.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2015</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/PowerletsDisag-AAAI15-Ehsan.pdf" title="Energy Disaggregation via Learning ‘Powerlets’ and Sparse Coding">
								Energy Disaggregation via Learning ‘Powerlets’ and Sparse Coding							</a>
												</h3>
												<p>Energy Disaggregation via Learning ‘Powerlets’ and Sparse Coding, E. Elhamifar and S. Sastry, AAAI Conference on Artificial Intelligence (AAAI), 2015.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>In this paper, we consider the problem of energy disaggregation, i.e., decomposing a whole home electricity signal into its component appliances. We propose a new supervised algorithm, which in the learning stage, automatically extracts signature consumption patterns of each device by modeling the device as a mixture of dynamical systems. In order to extract signature consumption patterns of a device corresponding to its different modes of operation, we define appropriate dissimilarities between energy snippets of the device and use them in a subset selection scheme, which we generalize to deal with time-series data. We then form a dictionary that consists of extracted power signatures across all devices. We cast the disaggregation problem as an optimization over a representation in the learned dictionary and incorporate several novel priors such as device-sparsity, knowledge about devices that do or do not work together as well as temporal consistency of the disaggregated solution. Real experiments on a publicly available energy dataset demonstrate that our proposed algorithm achieves promising results for energy disaggregation.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2014</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/RobustSubspaceClustering.pdf" title="Robust Subspace Clustering">
								Robust Subspace Clustering							</a>
												</h3>
												<p>Robust Subspace Clustering, M. Soltanolkotabi, E. Elhamifar and E. J. Candes, Annals of Statistics, 2014.</p>
												<div class="publication-abstract">
							<h2>Abstract</h2>
<p>Subspace clustering refers to the task of finding a multi-subspace representation that best fits a collection of points taken from a high-dimensional space. This paper introduces an algorithm inspired by sparse subspace clustering (SSC) [18] to cluster noisy data, and develops some novel theory demonstrating its correctness. In particular, the theory uses ideas from geometric functional analysis to show that the algorithm can accurately recover the underlying subspaces under minimal requirements on their orientation, and on the number of samples per subspace. Synthetic as well as real data experiments complement our theoretical study, illustrating our approach and demonstrating its effectiveness.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2013</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://arxiv.org/abs/1203.1005" title="Sparse Subspace Clustering: Algorithm, Theory, and Applications">
								Sparse Subspace Clustering: Algorithm, Theory, and Applications							</a>
												</h3>
												<p>Sparse Subspace Clustering: Algorithm, Theory, and Applications, E. Elhamifar and R. Vidal, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2013.</p>
												<div class="publication-abstract">
							<p>In many real-world problems, we are dealing with collections of high-dimensional data, such as images, videos, text and web documents, DNA microarray data, and more. Often, high-dimensional data lie close to low-dimensional structures corresponding to several classes or categories the data belongs to. In this paper, we propose and study an algorithm, called Sparse Subspace Clustering (SSC), to cluster data points that lie in a union of low-dimensional subspaces. The key idea is that, among infinitely many possible representations of a data point in terms of other points, a sparse representation corresponds to selecting a few points from the same subspace. This motivates solving a sparse optimization program whose solution is used in a spectral clustering framework to infer the clustering of data into subspaces. Since solving the sparse optimization program is in general NP-hard, we consider a convex relaxation and show that, under appropriate conditions on the arrangement of subspaces and the distribution of data, the proposed minimization program succeeds in recovering the desired sparse representations. The proposed algorithm can be solved efficiently and can handle data points near the intersections of subspaces. Another key advantage of the proposed algorithm with respect to the state of the art is that it can deal with data nuisances, such as noise, sparse outlying entries, and missing entries, directly by incorporating the model of the data into the sparse optimization program. We demonstrate the effectiveness of the proposed algorithm through experiments on synthetic data as well as the two real-world problems of motion segmentation and face clustering.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/CPAL-ICCV13-Ehsan.pdf" title="A Convex Optimization Framework for Active Learning">
								A Convex Optimization Framework for Active Learning							</a>
												</h3>
												<p>A Convex Optimization Framework for Active Learning, E. Elhamifar, G. Sapiro, A. Yang and S. Sastry, International Conference on Computer Vision (ICCV), 2013.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>In many image/video/web classification problems, we have access to a large number of unlabeled samples. However, it is typically expensive and time consuming to obtain labels for the samples. Active learning is the problem of progressively selecting and annotating the most informative unlabeled samples, in order to obtain a high classi- fication performance. Most existing active learning algorithms select only one sample at a time prior to retraining the classifier. Hence, they are computationally expensive and cannot take advantage of parallel labeling systems such as Mechanical Turk. On the other hand, algorithms that allow the selection of multiple samples prior to retraining the classifier, may select samples that have significant information overlap or they involve solving a non-convex optimization. More importantly, the majority of active learning algorithms are developed for a certain classifier type such as SVM. In this paper, we develop an efficient active learning framework based on convex programming, which can select multiple samples at a time for annotation. Unlike the state of the art, our algorithm can be used in conjunction with any type of classifiers, including those of the family of the recently proposed Sparse Representation-based Classification (SRC). We use the two principles of classi- fier uncertainty and sample diversity in order to guide the optimization program towards selecting the most informative unlabeled samples, which have the least information overlap. Our method can incorporate the data distribution in the selection process by using the appropriate dissimilarity between pairs of samples. We show the effectiveness of our framework in person detection, scene categorization and face recognition on real-world datasets.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2012</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://arxiv.org/abs/1104.0654" title="Block-Sparse Recovery via Convex Optimization">
								Block-Sparse Recovery via Convex Optimization							</a>
												</h3>
												<p>Block-Sparse Recovery via Convex Optimization, E. Elhamifar and R. Vidal, IEEE Transactions on Signal Processing (TSP), 2012.</p>
												<div class="publication-abstract">
							<p>Given a dictionary that consists of multiple blocks and a signal that lives in the range space of only a few blocks, we study the problem of finding a block-sparse representation of the signal, i.e., a representation that uses the minimum number of blocks. Motivated by signal/image processing and computer vision applications, such as face recognition, we consider the block-sparse recovery problem in the case where the number of atoms in each block is arbitrary, possibly much larger than the dimension of the underlying subspace. To find a block-sparse representation of a signal, we propose two classes of non-convex optimization programs, which aim to minimize the number of nonzero coefficient blocks and the number of nonzero reconstructed vectors from the blocks, respectively. Since both classes of problems are NP-hard, we propose convex relaxations and derive conditions under which each class of the convex programs is equivalent to the original non-convex formulation. Our conditions depend on the notions of mutual and cumulative subspace coherence of a dictionary, which are natural generalizations of existing notions of mutual and cumulative coherence. We evaluate the performance of the proposed convex programs through simulations as well as real experiments on face recognition. We show that treating the face recognition problem as a block-sparse recovery problem improves the state-of-the-art results by 10% with only 25% of the training data.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/Exemplars-NIPS12-Ehsan.pdf" title="Finding Exemplars from Pairwise Dissimilarities via Simultaneous Sparse Recovery">
								Finding Exemplars from Pairwise Dissimilarities via Simultaneous Sparse Recovery							</a>
												</h3>
												<p>Finding Exemplars from Pairwise Dissimilarities via Simultaneous Sparse Recovery, E. Elhamifar, G. Sapiro and R. Vidal, Neural Information Processing Systems (NIPS), 2012.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>Given pairwise dissimilarities between data points, we consider the problem of finding a subset of data points, called representatives or exemplars, that can efficiently describe the data collection. We formulate the problem as a row-sparsity regularized trace minimization problem that can be solved efficiently using convex programming. The solution of the proposed optimization program finds the representatives and the probability that each data point is associated with each one of the representatives. We obtain the range of the regularization parameter for which the solution of the proposed optimization program changes from selecting one representative for all data points to selecting all data points as representatives. When data points are distributed around multiple clusters according to the dissimilarities, we show that the data points in each cluster select representatives only from that cluster. Unlike metric-based methods, our algorithm can be applied to dissimilarities that are asymmetric or violate the triangle inequality, i.e., it does not require that the pairwise dissimilarities come from a metric. We demonstrate the effectiveness of the proposed algorithm on synthetic data as well as real-world image and text data.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/SMRS-CVPR12-Ehsan.pdf" title="See All by Looking at A Few: Sparse Modeling for Finding Representative Objects">
								See All by Looking at A Few: Sparse Modeling for Finding Representative Objects							</a>
												</h3>
												<p>See All by Looking at A Few: Sparse Modeling for Finding Representative Objects, E. Elhamifar, G. Sapiro and R. Vidal, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>We consider the problem of finding a few representatives for a dataset, i.e., a subset of data points that efficiently describes the entire dataset. We assume that each data point can be expressed as a linear combination of the representatives and formulate the problem of finding the representatives as a sparse multiple measurement vector problem. In our formulation, both the dictionary and the measurements are given by the data matrix, and the unknown sparse codes select the representatives via convex optimization. In general, we do not assume that the data are lowrank or distributed around cluster centers. When the data do come from a collection of low-rank models, we show that our method automatically selects a few representatives from each low-rank model. We also analyze the geometry of the representatives and discuss their relationship to the vertices of the convex hull of the data. We show that our framework can be extended to detect and reject outliers in datasets, and to efficiently deal with new observations and large datasets. The proposed framework and theoretical foundations are illustrated with examples in video summarization and image classification using representatives.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-30618-1_17" title="Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation">
								Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation							</a>
												</h3>
												<p>Sparse Hidden Markov Models for Surgical Gesture Classification and Skill Evaluation, L. Tao, E. Elhamifar, S. Khudanpur, G. Hager, and R. Vidal, Information Processing in Computer Assisted Interventions (IPCAI), 2012.</p>
												<div class="publication-abstract">
							<h4 class="Heading">Abstract</h4>
<p class="Para">We consider the problem of classifying surgical gestures and skill level in robotic surgical tasks. Prior work in this area models gestures as states of a hidden Markov model (HMM) whose observations are discrete, Gaussian or factor analyzed. While successful, these approaches are limited in expressive power due to the use of discrete or Gaussian observations. In this paper, we propose a new model called sparse HMMs whose observations are sparse linear combinations of elements from a dictionary of basic surgical motions. Given motion data from many surgeons with different skill levels, we propose an algorithm for learning a dictionary for each gesture together with an HMM grammar describing the transitions among different gestures. We then use these dictionaries and the grammar to represent and classify new motion data. Experiments on a database of surgical motions acquired with the da Vinci system show that our method performs on par with or better than state-of-the-art methods.This suggests that learning a grammar based on sparse motion dictionaries is important in gesture and skill classification.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2011</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/SMCE-NIPS11-Ehsan.pdf" title="Sparse Manifold Clustering and Embedding">
								Sparse Manifold Clustering and Embedding							</a>
												</h3>
												<p>Sparse Manifold Clustering and Embedding, E. Elhamifar and R. Vidal, Neural Information Processing Systems (NIPS), 2011.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>We propose an algorithm called Sparse Manifold Clustering and Embedding (SMCE) for simultaneous clustering and dimensionality reduction of data lying in multiple nonlinear manifolds. Similar to most dimensionality reduction methods, SMCE finds a small neighborhood around each data point and connects each point to its neighbors with appropriate weights. The key difference is that SMCE finds both the neighbors and the weights automatically. This is done by solving a sparse optimization problem, which encourages selecting nearby points that lie in the same manifold and approximately span a low-dimensional affine subspace. The optimal solution encodes information that can be used for clustering and dimensionality reduction using spectral clustering and embedding. Moreover, the size of the optimal neighborhood of a data point, which can be different for different points, provides an estimate of the dimension of the manifold to which the point belongs. Experiments demonstrate that our method can effectively handle multiple manifolds that are very close to each other, manifolds with non-uniform sampling and holes, as well as estimate the intrinsic dimensions of the manifolds.</p>
						</div>
					</div>
				</article>
				<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/SSRC-CVPR11-Ehsan.pdf" title="Robust Classification using Structured Sparse Representation">
								Robust Classification using Structured Sparse Representation							</a>
												</h3>
												<p>Robust Classification using Structured Sparse Representation, E. Elhamifar and R. Vidal, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2011.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>In many problems in computer vision, data in multiple classes lie in multiple low-dimensional subspaces of a highdimensional ambient space. However, most of the existing classification methods do not explicitly take this structure into account. In this paper, we consider the problem of classification in the multi-subspace setting using sparse representation techniques. We exploit the fact that the dictionary of all the training data has a block structure where the training data in each class form few blocks of the dictionary. We cast the classification as a structured sparse recovery problem where our goal is to find a representation of a test example that uses the minimum number of blocks from the dictionary. We formulate this problem using two different classes of non-convex optimization programs. We propose convex relaxations for these two non-convex programs and study conditions under which the relaxations are equivalent to the original problems. In addition, we show that the proposed optimization programs can be modified properly to also deal with corrupted data. To evaluate the proposed algorithms, we consider the problem of automatic face recognition. We show that casting the face recognition problem as a structured sparse recovery problem can improve the results of the state-of-the-art face recognition algorithms, especially when we have relatively small number of training data for each class. In particular, we show that the new class of convex programs can improve the state-ofthe-art face recognition results by 10% with only 25% of the training data. In addition, we show that the algorithms are robust to occlusion, corruption, and disguise.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
																					<div class="accordion-item">
								<h3 class="accordion-label">2009</h3>
								<div class="accordion-content">
													<article class="publication">
					<div class="publication-content">
						<h3 class="publication-title">
													<a href="http://www.ccs.neu.edu/home/eelhami/publications/SSC-CVPR09-Ehsan.pdf" title="Sparse Subspace Clustering">
								Sparse Subspace Clustering							</a>
												</h3>
												<p>Sparse Subspace Clustering, E. Elhamifar and R. Vidal, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2009.</p>
												<div class="publication-abstract">
							<p>Abstract</p>
<p>We propose a method based on sparse representation (SR) to cluster data drawn from multiple low-dimensional linear or affine subspaces embedded in a high-dimensional space. Our method is based on the fact that each point in a union of subspaces has a SR with respect to a dictionary formed by all other data points. In general, finding such a SR is NP hard. Our key contribution is to show that, under mild assumptions, the SR can be obtained ’exactly’ by using !1 optimization. The segmentation of the data is obtained by applying spectral clustering to a similarity matrix built from this SR. Our method can handle noise, outliers as well as missing data. We apply our subspace clustering algorithm to the problem of segmenting multiple motions in video. Experiments on 167 video sequences show that our approach significantly outperforms state-of-the-art methods.</p>
						</div>
					</div>
				</article>
								</div>
							</div>
													</div>
					</section>
	

							<section class="related-news-events related-section">
												<div class="section-inner">
							<h2 class="section-title">
								Related News
							</h2>
															<div class="news">
									<h3>
										<a href="https://www.khoury.northeastern.edu/research/darpa-young-faculty-award-granted-to-dr-ehsan-elhamifar/">DARPA Young Faculty Award granted to Dr. Ehsan Elhamifar</a>									</h3>
								</div>
													</div>
						
													</section>
	
							<section class="current-students related-people related-section">
						<div class="section-inner">
							<h2 class="section-title">
								Khoury PhD Students &amp; Post-Docs
							</h2>
							<div class="row">
															<div class="grid-people">
													<article class="people">
					<div class="grid-item">
						<a href="https://www.khoury.northeastern.edu/people/dat-huynh/">
								<div class="grid-image"><img src="https://www.khoury.northeastern.edu/wp-content/uploads/2017/10/phd-index-6836.jpg" alt="" /></div>
															<p class="roles"><span class="role-32">PhD Students</span></p>
														<h3 class="person-name">
									Dat Huynh							</h3>
						</a>
												<div class="position-list">
															<p class="position">PhD Student</p>
													</div>
																	</div>
				</article>
								</div>
															<div class="grid-people">
													<article class="people">
					<div class="grid-item">
						<a href="https://www.khoury.northeastern.edu/people/zijia-lu/">
								<div class="grid-image"><img src="https://www.khoury.northeastern.edu/wp-content/uploads/2019/11/100919-PhD-0142-index.jpg" alt="" /></div>
															<p class="roles"><span class="role-32">PhD Students</span></p>
														<h3 class="person-name">
									Zijia Lu							</h3>
						</a>
												<div class="position-list">
															<p class="position">PhD Student</p>
													</div>
																	</div>
				</article>
								</div>
															<div class="grid-people">
													<article class="people">
					<div class="grid-item">
						<a href="https://www.khoury.northeastern.edu/people/yuhan-shen/">
								<div class="grid-image"><img src="https://www.khoury.northeastern.edu/wp-content/uploads/2019/11/100919-PhD-0178-index.jpg" alt="" /></div>
															<p class="roles"><span class="role-32">PhD Students</span></p>
														<h3 class="person-name">
									Yuhan Shen							</h3>
						</a>
												<div class="position-list">
															<p class="position">PhD Student</p>
													</div>
																	</div>
				</article>
								</div>
														</div>
						</div>
					</section>
	
						</article>

			</section>
		</div><!-- / .row -->
	</main>
<footer role="contentinfo" id="site-footer">
	<div class="container">
		<div id="menu-prefooter" class="row">
			<div class="footer-logo">
				<!-- Khoury College wordmark only -->
				<svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
					 viewBox="0 0 323 20.5" style="enable-background:new 0 0 323 20.5;" xml:space="preserve">
				<style type="text/css">
					.st0{fill:#625445;}
				</style>
				<g>
					<path class="st0" d="M0,0.3h2.6v7h0l4.9-7h2.8L5.7,7.1l5.1,9.3H7.9L4,9.2l-1.4,2v5.2H0V0.3z"/>
					<path class="st0" d="M11.5,0.3h2.4v5.3l0.1,0c0.6-1,1.8-1.7,3-1.7c1.8,0,3,0.8,3,3.3v9.1h-2.4V8.1c0-1.6-0.5-2.2-1.7-2.2
						c-1,0-1.9,0.8-1.9,2.4v8.1h-2.4L11.5,0.3z"/>
					<path class="st0" d="M26.4,4c3.5,0,4.5,2.6,4.5,6.4s-1.1,6.4-4.5,6.4s-4.5-2.6-4.5-6.4S22.9,4,26.4,4z M26.4,14.9
						c1.8,0,2.1-1.5,2.1-4.6c0-2.7-0.3-4.6-2.1-4.6c-1.8,0-2.1,1.9-2.1,4.6C24.3,13.4,24.6,14.9,26.4,14.9z"/>
					<path class="st0" d="M39,15L39,15c-0.7,1.1-1.9,1.8-3.2,1.7c-1.8,0-3-0.8-3-4V4.3h2.4V13c0,1.3,0.6,1.8,1.6,1.8c1,0,2-0.7,2-2V4.3
						h2.4v12.1h-2.3L39,15z"/>
					<path class="st0" d="M43.6,4.3H46v1.9h0C46.6,4.8,47.5,4,48.9,4c0.2,0,0.4,0,0.6,0.1v2.5c-0.3-0.1-0.7-0.1-1-0.1
						c-1.1,0-2.4,0.5-2.4,2.7v7.3h-2.4L43.6,4.3z"/>
					<path class="st0" d="M52.7,4.3l2.1,9.1h0l1.9-9.1h2.5L56,16.8c-0.9,3.3-1.7,3.7-4.2,3.7c-0.3,0-0.6,0-1-0.1v-1.9
						c0.3,0.1,0.5,0.1,0.8,0.1c0.8,0,1.4-0.2,1.6-0.9l0.3-1L50.1,4.3L52.7,4.3z"/>
					<path class="st0" d="M76.1,10.6V11c0,2.9-1.2,5.7-4.9,5.7c-4,0-5.3-2.6-5.3-8.3S67.1,0,71.2,0C75.8,0,76,3.4,76,5v0.3h-2.6V5.1
						c0-1.5-0.4-3.2-2.3-3.1c-1.9,0-2.7,1.2-2.7,6.3s0.9,6.5,2.7,6.5c2.1,0,2.4-2.4,2.4-3.9v-0.3L76.1,10.6z"/>
					<path class="st0" d="M81.8,4c3.5,0,4.5,2.6,4.5,6.4s-1.1,6.4-4.5,6.4s-4.5-2.6-4.5-6.4S78.3,4,81.8,4z M81.8,14.9
						c1.8,0,2.1-1.5,2.1-4.6c0-2.7-0.3-4.6-2.1-4.6s-2.1,1.9-2.1,4.6C79.7,13.4,80,14.9,81.8,14.9z"/>
					<path class="st0" d="M88.3,0.3h2.4v16.1h-2.4V0.3z"/>
					<path class="st0" d="M93.3,0.3h2.4v16.1h-2.4V0.3z"/>
					<path class="st0" d="M100.3,10.6v0.7c0,1.6,0.2,3.7,2,3.7c1.7,0,1.9-2,1.9-2.7h2.3c0,2.7-1.6,4.4-4.3,4.4c-2,0-4.4-0.6-4.4-6.2
						c0-3.2,0.7-6.5,4.5-6.5c3.4,0,4.3,2,4.3,5.4v1.3L100.3,10.6z M104.2,9V8.3c0-1.5-0.5-2.7-1.9-2.7c-1.6,0-2,1.5-2,3.1V9L104.2,9z"/>
					<path class="st0" d="M111,17.4c0,0.7,0.7,1.4,1.8,1.4c1.3,0,2-0.9,2-2.3v-2h0c-0.5,1.1-1.6,1.7-2.7,1.7c-2.8,0-3.6-2.8-3.6-6.1
						c0-2.7,0.4-6.2,3.8-6.2c1.4,0,2.4,0.9,2.7,1.8h0V4.3h2.3v11.5c0,2.9-1.3,4.7-4.5,4.7c-3.6,0-4-2.1-4-3.1L111,17.4z M112.7,14.4
						c1.9,0,2.1-2.4,2.1-4.3c0-2-0.2-4.2-1.9-4.2c-1.8,0-2,1.8-2,4C110.8,12,110.9,14.4,112.7,14.4z"/>
					<path class="st0" d="M121.5,10.6v0.7c0,1.6,0.2,3.7,2,3.7c1.7,0,1.9-2,1.9-2.7h2.3c0,2.7-1.6,4.4-4.3,4.4c-2,0-4.4-0.6-4.4-6.2
						c0-3.2,0.7-6.5,4.5-6.5c3.4,0,4.3,2,4.3,5.4v1.3L121.5,10.6z M125.4,9V8.3c0-1.5-0.5-2.7-1.9-2.7c-1.6,0-2,1.5-2,3.1V9L125.4,9z"/>
					<path class="st0" d="M139.3,4c3.5,0,4.5,2.6,4.5,6.4s-1.1,6.4-4.5,6.4s-4.5-2.6-4.5-6.4S135.8,4,139.3,4z M139.3,14.9
						c1.8,0,2.1-1.5,2.1-4.6c0-2.7-0.3-4.6-2.1-4.6s-2.1,1.9-2.1,4.6C137.2,13.4,137.5,14.9,139.3,14.9z"/>
					<path class="st0" d="M146.4,6.1h-1.7V4.3h1.7V3.2c0-2.3,1.1-3,3.1-3c0.4,0,0.9,0,1.3,0.1v1.9h-0.7c-0.9,0-1.3,0.3-1.3,1.1v1.1h2
						v1.8h-2v10.3h-2.4L146.4,6.1z"/>
					<path class="st0" d="M167.3,10.6V11c0,2.9-1.2,5.7-4.9,5.7c-4,0-5.3-2.6-5.3-8.3s1.3-8.3,5.3-8.3c4.6,0,4.8,3.4,4.8,5v0.3h-2.6V5.1
						c0-1.5-0.5-3.2-2.3-3.1c-1.9,0-2.7,1.2-2.7,6.3s0.9,6.5,2.7,6.5c2.1,0,2.4-2.4,2.4-3.9v-0.3L167.3,10.6z"/>
					<path class="st0" d="M173,4c3.5,0,4.5,2.6,4.5,6.4s-1.1,6.4-4.5,6.4c-3.4,0-4.5-2.6-4.5-6.4S169.5,4,173,4z M173,14.9
						c1.8,0,2.1-1.5,2.1-4.6c0-2.7-0.3-4.6-2.1-4.6s-2.1,1.9-2.1,4.6C171,13.4,171.3,14.9,173,14.9z"/>
					<path class="st0" d="M179.5,4.3h2.3v1.4h0.1c0.6-1.1,1.7-1.7,2.9-1.7c1.7,0,2.5,0.8,2.8,1.8c0.7-1.2,1.6-1.8,3.1-1.8
						c1.7,0,2.9,0.9,2.9,3.2v9.2h-2.4V8.1c0-1.6-0.5-2.2-1.5-2.2c-1,0-1.9,0.8-1.9,2.4v8.1h-2.4V8.1c0-1.6-0.5-2.2-1.5-2.2
						c-1,0-1.9,0.8-1.9,2.4v8.1h-2.4L179.5,4.3z"/>
					<path class="st0" d="M196.1,4.3h2.3v1.5h0c0.5-1.1,1.4-1.8,2.7-1.8c2.8,0,3.9,2.4,3.9,6.5c0,5.1-2.1,6.2-3.7,6.2
						c-1.3,0-2.3-0.7-2.7-1.7h0v5.4h-2.4L196.1,4.3z M200.4,14.8c1.4,0,2-1,2-4.4c0-2.7-0.4-4.5-2-4.5c-1.7,0-2,1.7-2,4.3
						C198.4,13.1,198.7,14.8,200.4,14.8L200.4,14.8z"/>
					<path class="st0" d="M213.1,15L213.1,15c-0.7,1.1-1.9,1.8-3.2,1.7c-1.8,0-3-0.8-3-4V4.3h2.4V13c0,1.3,0.6,1.8,1.6,1.8
						c1,0,2-0.7,2-2V4.3h2.4v12.1h-2.3L213.1,15z"/>
					<path class="st0" d="M216.6,4.3h1.7V0.8h2.4v3.4h2v1.8h-2v7.2c0,0.9,0.3,1.3,1.1,1.3c0.3,0,0.6,0,0.9-0.1v1.8
						c-0.6,0.1-1.3,0.2-2,0.2c-1.6,0-2.5-0.4-2.5-2.9V6.1h-1.7L216.6,4.3z"/>
					<path class="st0" d="M226.1,10.6v0.7c0,1.6,0.2,3.7,2,3.7c1.7,0,1.9-2,1.9-2.7h2.3c0,2.7-1.6,4.4-4.3,4.4c-2,0-4.4-0.6-4.4-6.2
						c0-3.2,0.7-6.5,4.5-6.5c3.4,0,4.3,2,4.3,5.4v1.3L226.1,10.6z M230,9V8.3c0-1.5-0.5-2.7-1.9-2.7c-1.6,0-2,1.5-2,3.1V9L230,9z"/>
					<path class="st0" d="M234.4,4.3h2.4v1.9h0c0.5-1.3,1.4-2.2,2.8-2.2c0.2,0,0.4,0,0.6,0.1v2.5c-0.3-0.1-0.7-0.1-1-0.1
						c-1.1,0-2.4,0.5-2.4,2.7v7.3h-2.4L234.4,4.3z"/>
					<path class="st0" d="M249,11.4v0.4c0,2,0.9,2.9,2.6,2.9c1.6,0,2.4-1.1,2.4-2.3c0-1.7-0.9-2.4-2.3-2.9L250,9
						c-2.3-0.9-3.4-2.1-3.4-4.4c0-2.9,2-4.5,5-4.5c4.1,0,4.5,2.6,4.5,4.2v0.4h-2.6V4.3c0-1.5-0.7-2.3-2.3-2.3c-1.1,0-2.2,0.6-2.2,2.3
						c0,1.4,0.7,2.1,2.4,2.7l1.7,0.6c2.3,0.8,3.3,2,3.3,4.3c0,3.4-2.1,4.8-5.3,4.8c-4,0-4.9-2.7-4.9-4.9v-0.4H249z"/>
					<path class="st0" d="M266.7,12c-0.2,2.9-1.2,4.7-4.1,4.7c-3.5,0-4.5-2.6-4.5-6.4s1-6.4,4.5-6.4c3.6,0,4.2,2.8,4.2,4.3h-2.4
						c0-1.1-0.3-2.6-1.7-2.5c-1.8,0-2.1,1.9-2.1,4.6s0.3,4.6,2.1,4.6c1.3,0,1.8-1.1,1.8-2.9L266.7,12z"/>
					<path class="st0" d="M268.7,0.1h2.4v2.4h-2.4V0.1z M268.7,4.3h2.4v12.1h-2.4V4.3z"/>
					<path class="st0" d="M275.6,10.6v0.7c0,1.6,0.2,3.7,2,3.7c1.7,0,1.9-2,1.9-2.7h2.3c0,2.7-1.6,4.4-4.3,4.4c-2,0-4.4-0.6-4.4-6.2
						c0-3.2,0.7-6.5,4.5-6.5c3.4,0,4.3,2,4.3,5.4v1.3L275.6,10.6z M279.5,9V8.3c0-1.5-0.5-2.7-1.9-2.7c-1.6,0-2,1.5-2,3.1V9L279.5,9z"/>
					<path class="st0" d="M284,4.3h2.3v1.4h0.1c0.6-1.1,1.8-1.8,3.1-1.7c1.8,0,3,0.8,3,3.3v9.1H290V8.1c0-1.6-0.5-2.2-1.7-2.2
						c-1,0-1.9,0.8-1.9,2.4v8.1H284L284,4.3z"/>
					<path class="st0" d="M303,12c-0.2,2.9-1.1,4.7-4.1,4.7c-3.5,0-4.5-2.6-4.5-6.4s1-6.4,4.5-6.4c3.6,0,4.2,2.8,4.2,4.3h-2.4
						c0-1.1-0.3-2.6-1.7-2.5c-1.8,0-2.1,1.9-2.1,4.6s0.3,4.6,2.1,4.6c1.3,0,1.8-1.1,1.8-2.9L303,12z"/>
					<path class="st0" d="M306.9,10.6v0.7c0,1.6,0.2,3.7,2,3.7c1.7,0,1.9-2,1.9-2.7h2.3c0,2.7-1.6,4.4-4.3,4.4c-2,0-4.4-0.6-4.4-6.2
						c0-3.2,0.7-6.5,4.5-6.5c3.4,0,4.3,2,4.3,5.4v1.3L306.9,10.6z M310.8,9V8.3c0-1.5-0.5-2.7-1.9-2.7c-1.6,0-2,1.5-2,3.1V9L310.8,9z"/>
					<path class="st0" d="M320.4,7.8V7.5c0-1-0.3-1.9-1.6-1.9c-1,0-1.7,0.4-1.7,1.6c0,0.9,0.4,1.3,1.7,1.8l1.6,0.5
						c1.8,0.6,2.6,1.6,2.6,3.5c0,2.6-1.9,3.7-4.3,3.7c-3.1,0-4-1.4-4-3.8v-0.4h2.2v0.4c0,1.4,0.5,2.2,1.9,2.2c1.3,0,2-0.7,2-1.8
						c0-0.9-0.5-1.5-1.3-1.8l-2-0.7c-1.8-0.6-2.6-1.6-2.6-3.5c0-2.3,1.6-3.3,4.1-3.3c3.1,0,3.8,1.8,3.8,3.3v0.5L320.4,7.8z"/>
				</g>
				</svg>
        <span>Northeastern University</span>
			</div>
			<nav class="footer-nav" aria-label="Footer">
				<ul id="menu-action" class="menu menu-horizontal menu-action"><li id="menu-item-412" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-412"><a href="https://www.khoury.northeastern.edu/apply/">Apply</a></li>
<li id="menu-item-411" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-411"><a href="https://www.khoury.northeastern.edu/inquire/">Inquire</a></li>
<li id="menu-item-410" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-410"><a href="https://www.khoury.northeastern.edu/alumni-and-friends/give/">Give</a></li>
</ul><ul id="menu-contact" class="menu menu-horizontal"><li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-3010"><a rel="nofollow" href="#">Contact &#8211; Parent</a>
<ul class="sub-menu">
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-4598"><a href="https://www.khoury.northeastern.edu/directions-and-parking/">Directions &#038; Parking</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-2530"><a href="https://www.khoury.northeastern.edu/facilities/">Facilities</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-5831"><a href="https://www.khoury.northeastern.edu/systems/">Systems</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-4627"><a href="https://www.khoury.northeastern.edu/about/">About</a></li>
	<li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-6161"><a href="https://www.ccis.northeastern.edu/events/">Events</a></li>
	<li class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent menu-item-4629"><a href="https://www.khoury.northeastern.edu/news/">News</a></li>
</ul>
</li>
</ul><ul id="menu-social" class="menu menu-horizontal"><li id="menu-item-379" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-379"><a href="https://www.youtube.com/channel/UChz4r4VXwPxTqx083Am0IeQ">Youtube</a></li>
<li id="menu-item-380" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-380"><a href="http://www.twitter.com/khourycollege">Twitter</a></li>
<li id="menu-item-381" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-381"><a href="https://www.linkedin.com/groups/1943637">LinkedIn</a></li>
<li id="menu-item-383" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-383"><a href="http://www.instagram.com/khourycollege">Instagram</a></li>
<li id="menu-item-382" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-382"><a href="http://www.facebook.com/khourycollege">Facebook</a></li>
</ul>			</nav>
		</div><!-- / #menu-prefooter -->
	</div><!-- / .container -->
	<div id="menu-footer-area">
		<div class="container">
			<div class="row">
				<div class="footer-logo">
					<a href="http://www.northeastern.edu" target="_blank">
					<!-- northeastern wordmark only -->
					<svg version="1.1" id="nu_logo" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"  viewBox="0 0 500 50" style="enable-background:new 0 0 500 50;" xml:space="preserve">
						<style type="text/css"> .st2{fill:#FFFFFF;}</style>
						<g class="st2">
							<path d="M321.472,1.443v1.151c-5.079,0.367-5.079,3.037-5.079,7.328v9.788c0,4.554,0,6.805-1.36,9.318 c-1.833,3.348-5.968,5.967-12.196,5.967c-7.171,0-10.364-3.089-11.726-5.078c-1.727-2.565-1.727-4.973-1.727-10.835v-8.899 c0-7.014-0.052-7.59-4.658-7.59h-0.786V1.443h14.97v1.151c-5.181,0-5.338,0-5.338,7.486v9.159c0,4.973,0,7.747,1.308,9.945 c1.204,2.042,4.082,4.084,9.055,4.084c3.35,0,7.486-1.204,9.737-4.711c1.464-2.25,1.464-4.658,1.464-9.055V9.452 c0-4.188,0-6.491-5.285-6.858V1.443H321.472z"/>
							<path d="M327.174,12.592c0.417,1.204,0.626,3.245,0.68,4.344c2.668-2.931,5.025-4.344,8.06-4.344 c4.816,0,6.543,3.349,6.543,6.856v7.747c0,5.705,0,6.018,3.454,6.018v1.152h-10.731v-1.152c3.613,0,3.613-0.313,3.613-6.018v-6.752 c0-4.763-1.675-6.282-4.24-6.282c-2.985,0-4.921,2.513-6.7,4.502v8.532c0,5.653,0,6.018,3.454,6.018v1.152h-10.573v-1.152 c3.454,0,3.454-0.313,3.454-6.018v-6.23c0-5.705,0-6.019-3.454-6.019v-1.152c2.146-0.314,4.868-0.838,5.757-1.204H327.174z"/>
							<path d="M355.591,29.236c0,3.352,0.315,3.978,2.879,3.978h0.786v1.152h-11.149v-1.152h0.889 c2.67,0,3.193-0.418,3.193-3.978v-8.374c0-5.705-0.313-5.757-4.082-5.757v-1.152c1.57-0.052,4.764-0.732,6.962-1.36h0.523V29.236z" />
							<circle cx="353.371" cy="5.968" r="2.261"/>
							<path d="M371.136,35.204l-7.432-16.75c-1.362-3.036-1.884-3.769-3.821-3.874v-1.152h9.422v1.152 c-1.362,0-2.67,0-2.67,1.256c0,0.209,0.052,0.576,0.575,1.78l6.072,13.661l5.079-11.358c0.732-1.675,1.203-2.827,1.203-3.507 c0-1.57-1.623-1.781-2.565-1.833v-1.152h7.065v1.152c-2.198,0.157-3.035,2.094-4.658,5.653l-6.804,14.97H371.136z"/>
							<path d="M388.669,21.438c-0.054,0.472-0.105,1.204-0.105,1.57c0,6.647,2.094,10.836,7.171,10.836 c2.931,0,5.287-1.309,6.752-4.189h1.204c-1.308,3.455-4.397,5.549-8.637,5.549c-5.863,0-10.731-4.397-10.731-11.149 c0-6.491,4.24-11.463,10.521-11.463c5.915,0,8.9,3.873,9.055,8.845H388.669z M388.775,20.392h11.201 c-0.054-2.461-0.734-6.648-5.235-6.648C390.606,13.743,389.036,17.512,388.775,20.392z"/>
							<path d="M414.107,27.196c0,5.339,0,6.018,3.087,6.018h0.734v1.152H406.83v-1.152c3.612,0,3.612-0.208,3.612-6.018 v-5.915c0-5.811,0-6.019-3.612-6.019V14.11c2.355-0.314,5.077-1.152,5.915-1.414l0.367-0.104c0.261,0.837,0.734,2.513,0.734,5.495 c1.621-3.873,5.39-5.495,8.059-5.495c2.724,0,4.032,1.936,4.032,3.193c0,0.941-0.682,1.884-1.781,1.884 c-1.151,0-1.727-0.785-2.04-1.674c-0.211-0.576-0.628-1.57-1.833-1.57c-2.094,0-6.176,2.513-6.176,7.851V27.196z"/>
							<path d="M427.871,28.138h0.993c0.524,2.513,2.355,5.914,7.173,5.914c4.344,0,4.868-2.668,4.868-3.715 c0-2.565-2.722-3.769-6.02-4.973c-4.816-1.779-6.962-3.297-6.962-6.962c0-2.668,1.99-5.809,6.7-5.809 c2.459,0,4.24,0.994,5.444,2.198c0.417-0.471,0.941-1.727,0.993-1.833h0.943v6.491h-0.943c-0.471-2.407-2.565-5.705-6.28-5.705 c-3.404,0-4.555,1.675-4.555,3.194c0,2.46,1.988,3.349,5.811,4.71c4.186,1.467,7.379,3.194,7.379,7.381 c0,3.56-2.565,6.176-7.327,6.176c-3.089,0-4.921-1.204-6.124-2.356c-0.524,0.577-0.995,1.675-1.1,2.147h-0.993V28.138z"/>
							<path d="M454.25,29.236c0,3.352,0.313,3.978,2.878,3.978h0.786v1.152h-11.149v-1.152h0.889 c2.67,0,3.194-0.418,3.194-3.978v-8.374c0-5.705-0.315-5.757-4.084-5.757v-1.152c1.57-0.052,4.764-0.732,6.962-1.36h0.524V29.236z" />
							<circle cx="452.055" cy="5.968" r="2.261"/>
							<path d="M466.601,14.581v12.667c0,2.879,0,6.178,3.141,6.178c1.779,0,2.722-1.415,3.193-2.095l0.786,0.472 c-1.623,3.402-4.973,3.402-5.34,3.402c-1.464,0-2.616-0.315-3.454-0.994c-1.362-1.048-1.988-2.984-1.988-6.072V14.581H459.9v-1.152 c2.303-0.105,5.077-1.622,5.863-6.543h0.837v6.543h6.333v1.152H466.601z"/>
							<path d="M493.765,17.983c0.365-0.838,0.732-1.622,0.732-2.041c0-1.099-1.884-1.361-2.826-1.361v-1.152H499v1.152 c-2.618,0.157-3.142,1.466-4.449,4.606l-9.319,22.508c-1.362,3.245-2.616,5.548-4.658,5.548c-0.838,0-1.621-0.524-1.621-1.518 c0-1.727,1.727-2.513,2.668-2.931c1.781-0.786,2.357-1.099,3.089-2.931l1.988-4.973l-7.851-16.854 c-1.204-2.565-1.621-3.403-4.082-3.455v-1.152h9.63v1.152c-1.308,0.105-2.565,0.157-2.565,1.047c0,0.419,0.628,1.728,0.995,2.565 l5.757,12.248L493.765,17.983z"/>
							<path d="M7.857,4.245v23.449c0,3.455,0.732,5.392,6.071,5.549v1.151H1v-1.151c5.705-0.261,5.601-2.616,5.601-5.549 V9.741c0-6.648-0.366-7.119-5.129-7.119V1.472h9.421l19.629,26.066V7.595c0-2.775-0.366-4.921-5.915-4.973V1.472h12.562v1.151 c-5.077,0.471-5.391,2.251-5.391,5.338v27.218h-0.732L7.857,4.245z"/>
							<path d="M47.843,12.62c6.176,0,11.202,4.658,11.202,11.306c0,7.432-5.6,11.305-11.202,11.305 c-5.391,0-11.148-3.611-11.148-11.358C36.695,17.383,41.615,12.62,47.843,12.62z M47.843,33.976c4.816,0,6.962-3.297,6.962-9.892 c0-5.654-1.518-10.208-6.962-10.208c-5.286,0-6.909,4.45-6.909,10.155C40.934,30.73,43.081,33.976,47.843,33.976z"/>
							<path d="M68.36,27.223c0,5.338,0,6.019,3.088,6.019h0.732v1.151H61.084v-1.151c3.612,0,3.612-0.209,3.612-6.019v-5.915 c0-5.81,0-6.019-3.612-6.019v-1.152c2.356-0.314,5.078-1.152,5.915-1.413l0.366-0.105c0.262,0.837,0.733,2.512,0.733,5.495 c1.623-3.873,5.391-5.495,8.061-5.495c2.721,0,4.03,1.936,4.03,3.193c0,0.942-0.68,1.884-1.779,1.884 c-1.152,0-1.727-0.785-2.042-1.674c-0.209-0.575-0.628-1.57-1.832-1.57c-2.094,0-6.176,2.513-6.176,7.851V27.223z"/>
							<path d="M88.668,14.609v12.667c0,2.879,0,6.176,3.14,6.176c1.779,0,2.722-1.414,3.192-2.094l0.786,0.471 c-1.622,3.402-4.973,3.402-5.338,3.402c-1.466,0-2.618-0.315-3.455-0.994c-1.361-1.046-1.989-2.984-1.989-6.072V14.609h-3.036 v-1.152c2.303-0.104,5.077-1.621,5.862-6.543h0.838v6.543H95v1.152H88.668z"/>
							<path d="M119.548,27.223c0,5.758,0,6.019,3.558,6.019v1.151h-10.834v-1.151c3.611,0,3.611-0.261,3.611-6.019v-6.752 c0-4.869-1.465-6.281-4.554-6.281c-2.408,0-4.71,2.46-6.385,4.606v8.426c0,5.6,0,6.019,3.298,6.019v1.151H97.617v-1.151 c3.664,0,3.664-0.209,3.664-6.019V8.118c0-3.664,0-4.868-3.454-4.868V2.1c2.145,0,5.025-0.472,6.699-1.1h0.366v15.964 c2.617-2.774,4.92-4.344,7.642-4.344c4.658,0,7.014,2.46,7.014,7.223V27.223z"/>
							<path d="M128.287,21.465c-0.053,0.472-0.105,1.205-0.105,1.57c0,6.648,2.094,10.835,7.171,10.835 c2.931,0,5.287-1.309,6.753-4.188h1.203c-1.308,3.454-4.396,5.548-8.635,5.548c-5.863,0-10.731-4.397-10.731-11.148 c0-6.491,4.24-11.463,10.521-11.463c5.914,0,8.899,3.873,9.055,8.845H128.287z M128.392,20.418h11.2 c-0.052-2.46-0.732-6.647-5.234-6.647C130.224,13.772,128.654,17.54,128.392,20.418z"/>
							<path d="M167.367,30.573c-0.42,2.457-1.491,2.606-2.118,2.606c-1.623,0-1.651-1.15-1.651-4.752v-8.479 c0-3.089-0.399-7.328-7.623-7.328c-5.234,0-8.427,2.669-8.427,4.763c0,0.942,0.576,1.518,1.413,1.518 c1.361,0,1.885-0.995,2.199-2.146c0.365-1.414,1.151-2.983,4.501-2.983c3.925,0,4.396,2.513,4.396,5.6v1.308l-3.978,1.362 c-7.38,2.513-9.63,5.443-9.63,8.427c0,2.983,2.354,4.447,5.391,4.447c2.51,0,5.128-1.045,8.217-3.663 c0.262,1.256,0.942,3.663,4.011,3.663c2.879,0,4.136-1.987,4.24-4.343H167.367z M160.057,30.089 c-2.107,1.822-4.954,3.271-6.89,3.271c-2.221,0-3.302-1.609-3.302-3.54c0-2.895,2.733-5.523,7.174-6.971l3.018-0.963V30.089z"/>
							<path d="M170.439,28.165h0.994c0.523,2.513,2.355,5.914,7.171,5.914c4.345,0,4.867-2.668,4.867-3.715 c0-2.565-2.721-3.768-6.019-4.972c-4.815-1.779-6.962-3.297-6.962-6.962c0-2.668,1.99-5.809,6.7-5.809 c2.46,0,4.24,0.994,5.443,2.199c0.42-0.472,0.943-1.728,0.995-1.833h0.941v6.49h-0.941c-0.471-2.407-2.566-5.705-6.281-5.705 c-3.402,0-4.553,1.675-4.553,3.193c0,2.46,1.989,3.349,5.81,4.71c4.187,1.466,7.38,3.194,7.38,7.381c0,3.559-2.566,6.175-7.33,6.175 c-3.088,0-4.919-1.204-6.123-2.356c-0.523,0.577-0.993,1.675-1.098,2.147h-0.994V28.165z"/>
							<path d="M195.561,14.609v12.667c0,2.879,0,6.176,3.141,6.176c1.779,0,2.72-1.414,3.193-2.094l0.786,0.471 c-1.623,3.402-4.973,3.402-5.34,3.402c-1.466,0-2.616-0.315-3.454-0.994c-1.362-1.046-1.99-2.984-1.99-6.072V14.609h-3.035v-1.152 c2.303-0.104,5.077-1.621,5.863-6.543h0.837v6.543h6.334v1.152H195.561z"/>
							<path d="M208.226,21.465c-0.052,0.472-0.105,1.205-0.105,1.57c0,6.648,2.094,10.835,7.173,10.835 c2.93,0,5.285-1.309,6.751-4.188h1.204c-1.308,3.454-4.397,5.548-8.637,5.548c-5.861,0-10.731-4.397-10.731-11.148 c0-6.491,4.24-11.463,10.521-11.463c5.915,0,8.898,3.873,9.055,8.845H208.226z M208.332,20.418h11.201 c-0.054-2.46-0.734-6.647-5.235-6.647C210.163,13.772,208.593,17.54,208.332,20.418z"/>
							<path d="M233.034,27.223c0,5.338,0,6.019,3.089,6.019h0.734v1.151h-11.097v-1.151c3.613,0,3.613-0.209,3.613-6.019 v-5.915c0-5.81,0-6.019-3.613-6.019v-1.152c2.355-0.314,5.077-1.152,5.915-1.413l0.367-0.105c0.261,0.837,0.732,2.512,0.732,5.495 c1.623-3.873,5.39-5.495,8.06-5.495c2.722,0,4.03,1.936,4.03,3.193c0,0.942-0.678,1.884-1.779,1.884 c-1.151,0-1.727-0.785-2.04-1.674c-0.211-0.575-0.63-1.57-1.834-1.57c-2.092,0-6.176,2.513-6.176,7.851V27.223z"/>
							<path d="M253.133,12.62c0.417,1.204,0.628,3.245,0.68,4.344c2.668-2.931,5.024-4.344,8.06-4.344 c4.814,0,6.543,3.349,6.543,6.856v7.747c0,5.706,0,6.019,3.454,6.019v1.151H261.14v-1.151c3.611,0,3.611-0.313,3.611-6.019v-6.752 c0-4.763-1.675-6.281-4.238-6.281c-2.985,0-4.921,2.513-6.7,4.501v8.532c0,5.652,0,6.019,3.454,6.019v1.151h-10.573v-1.151 c3.454,0,3.454-0.313,3.454-6.019v-6.229c0-5.705,0-6.019-3.454-6.019v-1.152c2.147-0.314,4.868-0.838,5.757-1.204H253.133z"/>
						</g>
					</svg>

					<span>Khoury College of Computer Sciences</span>
					</a>
				</div><!-- / .footer-logo -->
				<div class="footer-nav">
					<nav id="menu-footer" class="menu-links-menu-container"><ul id="menu-links-menu" class="menu menu-horizontal"><li id="menu-item-377" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-377"><a href="http://my.northeastern.edu/">myNortheastern</a></li>
<li id="menu-item-2809" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-2809"><a href="https://prod-web.neu.edu/wasapp/employeelookup/public/main.action#_ga=1.152250297.1229401008.1453998512">Find Faculty &#038; Staff</a></li>
<li id="menu-item-2810" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-2810"><a href="http://www.northeastern.edu/neuhome/adminlinks/findaz.html">Find A-Z</a></li>
<li id="menu-item-2811" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-2811"><a href="http://www.northeastern.edu/emergency/index.html">Emergency Information</a></li>
<li id="menu-item-11292" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-11292"><a href="https://www.northeastern.edu/privacy-information/">Privacy</a></li>
<li id="menu-item-378" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-378"><a href="http://www.northeastern.edu/search/index.html">Search</a></li>
</ul></nav>					<div class="copy">
											<address><p>
							360 Huntington Ave. Boston, Massachusetts 02115							<a class="tel" href="tel:6173732000"><strong>617.373.2000</strong></a>
							<a class="tel" href="tel:6173733768"><strong>TTY: 617.373.3768</strong></a>
						</p></address>
						<p>© 2020 Northeastern University										</div><!-- / .copy -->
				</div><!-- / .footer-nav -->
			</div><!-- / .row -->
		</div><!-- / .container -->
	</div><!-- / #menu-footer -->
</footer>
<!-- as purely supplemental info, flyout is at the end. -->
<aside id="flyout">

	<h2 class="flyout-label">Look<br />
Inside:<br />
People</h2>
	<div class="flyout-content">

		<h3 class="flyout-title">People</h3>
		<div class="main-content">
			<h2>Scaling to meet growing demands</h2>
<p>The rise of computer science begets the need for more—and more diverse—expertise. Khoury College answers the call with highly talented faculty and dedicated advisors, coordinators, and staff.</p>
		</div>

			<div class="row">
			<div class="stripe-stat">
				<div class="stat-item"><h4>65%</h4><p>increase in tenure-track faculty over the past five years</p>
</div><div class="stat-item"><h4>27%</h4><p>of current tenure-track faculty are interdisciplinary with other colleges</p>
</div>			</div>
		</div>
			<div class="row">
			<div class="stripe-image">
				<img src="https://www.khoury.northeastern.edu/wp-content/uploads/2018/11/CCIS_interdisciplinary_faculty_2018.png" alt="" />			</div>
		</div>
			<div class="row">
			<div class="stripe-text">
				<p>“I joined CCIS to be at a place on the rise. There is an enormous opportunity for collaboration with highly motivated, smart faculty looking to do interesting, relevant work—and not caring about individual credit or traditional boundaries. We all want to be part of making something great.”<br />
<em>-David Choffnes, Assistant Professor</em></p>
			</div>
		</div>
	
	</div>
</aside>
	<script type="text/javascript">
	_linkedin_data_partner_id = "8239";
	</script><script type="text/javascript">
	(function(){var s = document.getElementsByTagName("script")[0];
	var b = document.createElement("script");
	b.type = "text/javascript";b.async = true;
	b.src = "https://snap.licdn.com/li.lms-analytics/insight.min.js";
	s.parentNode.insertBefore(b, s);})();
	</script>
	<noscript>
		<img height="1" width="1" style="display:none;" alt="" src="https://dc.ads.linkedin.com/collect/?pid=8239&fmt=gif" />
	</noscript>
			<script>
		( function ( body ) {
			'use strict';
			body.className = body.className.replace( /\btribe-no-js\b/, 'tribe-js' );
		} )( document.body );
		</script>
		<script> /* <![CDATA[ */var tribe_l10n_datatables = {"aria":{"sort_ascending":": activate to sort column ascending","sort_descending":": activate to sort column descending"},"length_menu":"Show _MENU_ entries","empty_table":"No data available in table","info":"Showing _START_ to _END_ of _TOTAL_ entries","info_empty":"Showing 0 to 0 of 0 entries","info_filtered":"(filtered from _MAX_ total entries)","zero_records":"No matching records found","search":"Search:","all_selected_text":"All items on this page were selected. ","select_all_link":"Select all pages","clear_selection":"Clear Selection.","pagination":{"all":"All","next":"Next","previous":"Previous"},"select":{"rows":{"0":"","_":": Selected %d rows","1":": Selected 1 row"}},"datepicker":{"dayNames":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"],"dayNamesShort":["Sun","Mon","Tue","Wed","Thu","Fri","Sat"],"dayNamesMin":["S","M","T","W","T","F","S"],"monthNames":["January","February","March","April","May","June","July","August","September","October","November","December"],"monthNamesShort":["January","February","March","April","May","June","July","August","September","October","November","December"],"monthNamesMin":["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"nextText":"Next","prevText":"Prev","currentText":"Today","closeText":"Done","today":"Today","clear":"Clear"}};/* ]]> */ </script><script type='text/javascript' src='https://www.khoury.northeastern.edu/wp-content/themes/ccis_theme/prod/prod.js?ver=5.3.2'></script>
<script type='text/javascript' src='https://www.khoury.northeastern.edu/wp-includes/js/wp-embed.min.js?ver=5.3.2'></script>
</body>
</html>
